<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Model Selection in High Dimensions</title>
  <meta name="description" content="This is the content of the course Model Selection. The output format for this project is bookdown::gitbook.">
  <meta name="generator" content="bookdown 0.5 and GitBook 2.6.7">

  <meta property="og:title" content="Model Selection in High Dimensions" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the content of the course Model Selection. The output format for this project is bookdown::gitbook." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Model Selection in High Dimensions" />
  
  <meta name="twitter:description" content="This is the content of the course Model Selection. The output format for this project is bookdown::gitbook." />
  

<meta name="author" content="Maria-Pia Victoria-Feser (professor), Cesare Miglioli and Guillaume Blanc (teaching assistants)">


<meta name="date" content="2018-03-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="ordering-the-variables.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#read-this-part-first"><i class="fa fa-check"></i><b>1.1</b> Read this part first</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#content-choice-and-structure"><i class="fa fa-check"></i><b>1.2</b> Content choice and structure</a><ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#bibliography"><i class="fa fa-check"></i><b>1.2.1</b> Bibliography</a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#useful-links"><i class="fa fa-check"></i><b>1.2.2</b> Useful links</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#using-r"><i class="fa fa-check"></i><b>1.3</b> Using R</a><ul>
<li class="chapter" data-level="1.3.1" data-path="index.html"><a href="index.html#useful-r-packages"><i class="fa fa-check"></i><b>1.3.1</b> Useful R packages</a></li>
<li class="chapter" data-level="1.3.2" data-path="index.html"><a href="index.html#managing-data"><i class="fa fa-check"></i><b>1.3.2</b> Managing Data</a></li>
<li class="chapter" data-level="1.3.3" data-path="index.html"><a href="index.html#loading-data-from-an-r-package"><i class="fa fa-check"></i><b>1.3.3</b> Loading data from an R package</a></li>
<li class="chapter" data-level="1.3.4" data-path="index.html"><a href="index.html#loading-data-from-a-local-file"><i class="fa fa-check"></i><b>1.3.4</b> Loading data from a local file</a></li>
<li class="chapter" data-level="1.3.5" data-path="index.html"><a href="index.html#loading-data-from-an-online-file"><i class="fa fa-check"></i><b>1.3.5</b> Loading data from an online file</a></li>
<li class="chapter" data-level="1.3.6" data-path="index.html"><a href="index.html#loading-data-from-an-online-database-using-a-mysql-query-optional"><i class="fa fa-check"></i><b>1.3.6</b> Loading data from an online database using a mySQL query (Optional)</a></li>
<li class="chapter" data-level="1.3.7" data-path="index.html"><a href="index.html#data-wrangling"><i class="fa fa-check"></i><b>1.3.7</b> Data Wrangling</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#writing-reports"><i class="fa fa-check"></i><b>1.4</b> Writing reports</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#r-markdown"><i class="fa fa-check"></i><b>1.4.1</b> R Markdown</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#github"><i class="fa fa-check"></i><b>1.4.2</b> GitHub</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#examples"><i class="fa fa-check"></i><b>1.5</b> Examples</a><ul>
<li class="chapter" data-level="1.5.1" data-path="index.html"><a href="index.html#data-on-malnutrition-in-zambia"><i class="fa fa-check"></i><b>1.5.1</b> Data on Malnutrition in Zambia</a></li>
<li class="chapter" data-level="1.5.2" data-path="index.html"><a href="index.html#prognostic-factors-in-childhood-leukemia"><i class="fa fa-check"></i><b>1.5.2</b> Prognostic Factors in Childhood Leukemia</a></li>
<li class="chapter" data-level="1.5.3" data-path="index.html"><a href="index.html#r-package-quantmod"><i class="fa fa-check"></i><b>1.5.3</b> R package quantmod</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#fundamental-statistical-concepts"><i class="fa fa-check"></i><b>1.6</b> Fundamental statistical concepts</a><ul>
<li class="chapter" data-level="1.6.1" data-path="index.html"><a href="index.html#sample-and-population"><i class="fa fa-check"></i><b>1.6.1</b> Sample and population</a></li>
<li class="chapter" data-level="1.6.2" data-path="index.html"><a href="index.html#models-and-risk"><i class="fa fa-check"></i><b>1.6.2</b> Models and risk</a></li>
<li class="chapter" data-level="1.6.3" data-path="index.html"><a href="index.html#estimators-and-associated-variability"><i class="fa fa-check"></i><b>1.6.3</b> Estimators and associated variability</a></li>
<li class="chapter" data-level="1.6.4" data-path="index.html"><a href="index.html#simulating-the-population-using-resampling-techniques"><i class="fa fa-check"></i><b>1.6.4</b> Simulating the population using resampling techniques</a></li>
<li class="chapter" data-level="1.6.5" data-path="index.html"><a href="index.html#model-selection"><i class="fa fa-check"></i><b>1.6.5</b> Model Selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html"><i class="fa fa-check"></i><b>2</b> Assessing the validity of a model</a><ul>
<li class="chapter" data-level="2.1" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#introduction-1"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#cross-validation"><i class="fa fa-check"></i><b>2.2</b> Cross-Validation</a></li>
<li class="chapter" data-level="2.3" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#covariance-penalties-criteria"><i class="fa fa-check"></i><b>2.3</b> Covariance Penalties Criteria</a><ul>
<li class="chapter" data-level="2.3.1" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#introduction-2"><i class="fa fa-check"></i><b>2.3.1</b> Introduction</a></li>
<li class="chapter" data-level="2.3.2" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#mallows-c_p"><i class="fa fa-check"></i><b>2.3.2</b> Mallows <span class="math inline">\(C_p\)</span></a></li>
<li class="chapter" data-level="2.3.3" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#efrons-q-class"><i class="fa fa-check"></i><b>2.3.3</b> Efron’s <span class="math inline">\(q\)</span>-class</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#information-theory-and-bayesian-criteria"><i class="fa fa-check"></i><b>2.4</b> Information Theory and Bayesian Criteria</a><ul>
<li class="chapter" data-level="2.4.1" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#aic-akaike-information-criterion"><i class="fa fa-check"></i><b>2.4.1</b> AIC: Akaike Information Criterion</a></li>
<li class="chapter" data-level="2.4.2" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#bic-bayesian-information-criterion"><i class="fa fa-check"></i><b>2.4.2</b> BIC: Bayesian Information Criterion</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#mean-squared-error-based-criteria"><i class="fa fa-check"></i><b>2.5</b> Mean Squared Error Based Criteria</a><ul>
<li class="chapter" data-level="2.5.1" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#steins-unbiased-risk-estimator-sure"><i class="fa fa-check"></i><b>2.5.1</b> Stein’s unbiased risk estimator (SURE)</a></li>
<li class="chapter" data-level="2.5.2" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#the-focused-information-criterion-fic"><i class="fa fa-check"></i><b>2.5.2</b> The Focused Information Criterion (FIC)</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#classification-measures"><i class="fa fa-check"></i><b>2.6</b> Classification measures</a><ul>
<li class="chapter" data-level="2.6.1" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#the-logistic-model"><i class="fa fa-check"></i><b>2.6.1</b> The logistic model</a></li>
<li class="chapter" data-level="2.6.2" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#prediction-error-measures-for-binary-classification"><i class="fa fa-check"></i><b>2.6.2</b> Prediction error measures for Binary classification</a></li>
<li class="chapter" data-level="2.6.3" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#classification-error-estimation"><i class="fa fa-check"></i><b>2.6.3</b> Classification error estimation</a></li>
<li class="chapter" data-level="2.6.4" data-path="assessing-the-validity-of-a-model.html"><a href="assessing-the-validity-of-a-model.html#the-roc-curve"><i class="fa fa-check"></i><b>2.6.4</b> The ROC curve</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ordering-the-variables.html"><a href="ordering-the-variables.html"><i class="fa fa-check"></i><b>3</b> Ordering the variables</a><ul>
<li class="chapter" data-level="3.1" data-path="ordering-the-variables.html"><a href="ordering-the-variables.html#introduction-3"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="ordering-the-variables.html"><a href="ordering-the-variables.html#stepwise-forward-regression"><i class="fa fa-check"></i><b>3.2</b> Stepwise forward regression</a><ul>
<li class="chapter" data-level="3.2.1" data-path="ordering-the-variables.html"><a href="ordering-the-variables.html#partial-correlations"><i class="fa fa-check"></i><b>3.2.1</b> Partial correlations</a></li>
<li class="chapter" data-level="3.2.2" data-path="ordering-the-variables.html"><a href="ordering-the-variables.html#selection-by-hypothesis-testing"><i class="fa fa-check"></i><b>3.2.2</b> Selection by hypothesis testing</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="solutions.html"><a href="solutions.html"><i class="fa fa-check"></i><b>4</b> Solutions</a><ul>
<li class="chapter" data-level="4.1" data-path="solutions.html"><a href="solutions.html#chapter-1"><i class="fa fa-check"></i><b>4.1</b> Chapter 1</a><ul>
<li class="chapter" data-level="4.1.1" data-path="solutions.html"><a href="solutions.html#zam"><i class="fa fa-check"></i><b>4.1.1</b> Data on Malnutrition in Zambia</a></li>
<li class="chapter" data-level="4.1.2" data-path="solutions.html"><a href="solutions.html#leuk"><i class="fa fa-check"></i><b>4.1.2</b> Prognostic Factors in Childhood Leukemia</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="solutions.html"><a href="solutions.html#chapter-2"><i class="fa fa-check"></i><b>4.2</b> Chapter 2</a><ul>
<li class="chapter" data-level="4.2.1" data-path="solutions.html"><a href="solutions.html#cv"><i class="fa fa-check"></i><b>4.2.1</b> Cross-validation</a></li>
<li class="chapter" data-level="4.2.2" data-path="solutions.html"><a href="solutions.html#aic"><i class="fa fa-check"></i><b>4.2.2</b> Akaike Information Criterion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Model Selection in High Dimensions</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="solutions" class="section level1">
<h1><span class="header-section-number">4</span> Solutions</h1>
<div id="chapter-1" class="section level2">
<h2><span class="header-section-number">4.1</span> Chapter 1</h2>
<div id="zam" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Data on Malnutrition in Zambia</h3>
<blockquote>
<ul>
<li>Load the dataset and build the variables so that they can be used for a regression analysis.</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">require</span>(foreign)  <span class="co"># install foreign package if you do not have it yet</span>

<span class="co"># See section 1.6.2 e-book for information on the dataset.</span>

<span class="co"># dat = read.spss(&quot;Zambia.SAV&quot;, add.undeclared.levels = &quot;no&quot;)</span>

dat =<span class="st"> </span><span class="kw">read.spss</span>(<span class="st">&quot;Zambia.SAV&quot;</span>)

<span class="co"># Construct system matrix</span>

<span class="co"># The idea behind this exercise is to be aware that data cleaning is most of the times the real issue </span>
<span class="co"># with a real problem. It is sensitive to say that 80% of the work is cleaning and only 20% is modeling.</span>

<span class="co"># Extract response variable i.e. HW70 Height for age standard deviation (according to WHO)</span>
y =<span class="st"> </span>dat$HW70
y[y ==<span class="st"> </span><span class="dv">9996</span>] =<span class="st"> </span><span class="ot">NA</span>
y[y ==<span class="st"> </span><span class="dv">9997</span>] =<span class="st"> </span><span class="ot">NA</span>
y[y ==<span class="st"> </span><span class="dv">9998</span>] =<span class="st"> </span><span class="ot">NA</span>
y[y ==<span class="st"> </span><span class="dv">9999</span>] =<span class="st"> </span><span class="ot">NA</span>

<span class="co"># Revert tranformation (i.e. z-score)</span>
y =<span class="st"> </span>y/<span class="dv">100</span>

<span class="co"># Variable 1: The calculated months of breastfeeding gives the duration of breastfeeding</span>
x1 =<span class="st"> </span>dat$M5
x1[x1 ==<span class="st"> </span><span class="dv">94</span>] =<span class="st"> </span><span class="dv">0</span>
x1[x1 ==<span class="st"> </span><span class="dv">97</span>] =<span class="st"> </span><span class="ot">NA</span>
x1[x1 ==<span class="st"> </span><span class="dv">98</span>] =<span class="st"> </span><span class="ot">NA</span>
x1[x1 ==<span class="st"> </span><span class="dv">99</span>] =<span class="st"> </span><span class="ot">NA</span>
x1[x1 &gt;<span class="st"> </span><span class="dv">40</span>] =<span class="st"> </span><span class="ot">NA</span>

<span class="co"># Variable 2: Age in months of the child</span>
x2 =<span class="st"> </span>dat$HW1

<span class="co"># Variable 3: Age of the mother at birth</span>
x3 =<span class="st"> </span>dat$V012 -<span class="st"> </span>dat$B8
x3[x3&gt;<span class="dv">45</span>] =<span class="st"> </span><span class="ot">NA</span>

<span class="co"># Variable 4: Body mass index (BMI) of the mother</span>
x4 =<span class="st"> </span>dat$V445

x4 =<span class="st"> </span>x4/<span class="dv">100</span>  <span class="co"># no sense without this division</span>

<span class="co"># Variable 5: Height of the mother in meters</span>
x5 =<span class="st"> </span>dat$V438
x5[x5 ==<span class="st"> </span><span class="dv">9998</span>] =<span class="st"> </span><span class="ot">NA</span>
x5[x5 ==<span class="st"> </span><span class="dv">9999</span>] =<span class="st"> </span><span class="ot">NA</span>
x5[x5 &lt;<span class="st"> </span><span class="dv">1300</span>] =<span class="st"> </span><span class="ot">NA</span>
x5[x5 &gt;<span class="st"> </span><span class="dv">1900</span>] =<span class="st"> </span><span class="ot">NA</span>

x5 =<span class="st"> </span>x5/<span class="dv">1000</span>  <span class="co"># it was in mm, we need to transform from original</span>

<span class="co"># Variable 6: Weight of the mother in kilograms</span>
x6 =<span class="st"> </span>dat$V437

x6=x6/<span class="dv">10</span> <span class="co"># we need to go back to Kg</span>

<span class="co"># Variable 7: De facto region of residence</span>

<span class="co"># Creating dummies (i.e. indicator functions) for each level of an existing factor enables</span>
<span class="co"># to check the coefficients of each level in a possible future model estimation</span>

x7 =<span class="st"> </span><span class="kw">as.factor</span>(dat$V101)


x7 =<span class="st"> </span><span class="kw">model.matrix</span>(~x7<span class="dv">-1</span>)

<span class="kw">dim</span>(x7)

<span class="co"># Variable 8: Mother highest education level attended</span>
x8 =<span class="st"> </span><span class="kw">as.factor</span>(dat$V106)
x8 =<span class="st"> </span><span class="kw">model.matrix</span>(~x8<span class="dv">-1</span>)

<span class="kw">dim</span>(x8)

<span class="co"># Variable 9: Wealth index factor score</span>
x9 =<span class="st"> </span>dat$V191

<span class="co"># Variable 10: Weight of child at birth given in kilograms with three implied decimal places</span>
x10 =<span class="st"> </span>dat$M19
x10[x10 ==<span class="st"> </span><span class="dv">9996</span>] =<span class="st"> </span><span class="ot">NA</span>
x10[x10 ==<span class="st"> </span><span class="dv">9997</span>] =<span class="st"> </span><span class="ot">NA</span>
x10[x10 ==<span class="st"> </span><span class="dv">9998</span>] =<span class="st"> </span><span class="ot">NA</span>
x10[x10 ==<span class="st"> </span><span class="dv">9999</span>] =<span class="st"> </span><span class="ot">NA</span>
x10 =<span class="st"> </span>x10/<span class="dv">1000</span>

<span class="co"># Variable 11: Child Sex</span>
x11 =<span class="st"> </span>dat$B4

<span class="co"># Variable 12: Preceding birth interval is calculated as the difference in months between the current birth and the previous birth</span>
x12 =<span class="st"> </span>dat$B11
x12[x12 &gt;<span class="st"> </span><span class="dv">125</span>] =<span class="st"> </span><span class="ot">NA</span>

<span class="co"># Variable 13: Drinking Water</span>
x13 =<span class="st"> </span>dat$V113
x13 =<span class="st"> </span><span class="kw">model.matrix</span>(~x13<span class="dv">-1</span>)
x13 =<span class="st"> </span>x13[,<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">13</span>,<span class="dv">17</span>,<span class="dv">18</span>)]

<span class="kw">dim</span>(x13)

<span class="kw">levels</span>(x13)

mat.sys =<span class="st"> </span><span class="kw">na.omit</span>(<span class="kw">cbind</span>(y,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13))
<span class="kw">dim</span>(mat.sys)[<span class="dv">2</span>]


<span class="co"># Number of regressor</span>
p =<span class="st"> </span><span class="kw">dim</span>(mat.sys)[<span class="dv">2</span>]

<span class="co"># Construct X and Y</span>
y =<span class="st"> </span>mat.sys[,<span class="dv">1</span>]
X =<span class="st"> </span>mat.sys[,<span class="dv">2</span>:p]

<span class="co"># Create a dataframe</span>

data_zambia =<span class="st"> </span><span class="kw">cbind</span>(y,X)

data_zambia =<span class="st"> </span><span class="kw">data.frame</span>(data_zambia)</code></pre></div>
<blockquote>
<ul>
<li>Associate proper names to each variable (hint: look at the previous comments in the r chunk).</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colnames</span>(data_zambia) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;Height for age sd&quot;</span>, <span class="st">&quot;Breastfeeding duration (months)&quot;</span>,<span class="st">&quot;Age of the child (months)&quot;</span>, <span class="st">&quot;Age of the mother (years)&quot;</span>, <span class="st">&quot;BMI mother&quot;</span>, <span class="st">&quot;Heigth mother (meter)&quot;</span>, <span class="st">&quot;Weight mother (kg)&quot;</span>, <span class="st">&quot;Region:Central&quot;</span>, <span class="st">&quot;Region:Copperbelt&quot;</span>, <span class="st">&quot;Region:Eastern&quot;</span>, <span class="st">&quot;Region:Luapula&quot;</span>, <span class="st">&quot;Region:Lusaka&quot;</span>, <span class="st">&quot;Region:Northern&quot;</span>, <span class="st">&quot;Region:Northwestern&quot;</span>, <span class="st">&quot;Region:Southern&quot;</span>, <span class="st">&quot;Region:Western&quot;</span>, <span class="st">&quot;Ed:No education&quot;</span>, <span class="st">&quot;Ed:Primary&quot;</span>, <span class="st">&quot;Ed:Secondary&quot;</span>, <span class="st">&quot;Ed:Higher&quot;</span>, <span class="st">&quot;Wealth index factor score&quot;</span>, <span class="st">&quot;Child weight at birth (kg)&quot;</span>, <span class="st">&quot;Child sex&quot;</span>, <span class="st">&quot;Interval between births&quot;</span>,<span class="st">&quot;Water:Piped into dwelling&quot;</span>, <span class="st">&quot;Water:Piped to yard/plot&quot;</span>, <span class="st">&quot;Water:Public tap/standpipe&quot;</span>, <span class="st">&quot;Water:Protected well&quot;</span>, <span class="st">&quot;Water:Unprotected well&quot;</span>, <span class="st">&quot;Water:River/dam/lake/ponds/stream/canal/irrigation channel&quot;</span>, <span class="st">&quot;Water:Bottled water&quot;</span>, <span class="st">&quot;Water:Other&quot;</span>)</code></pre></div>
<blockquote>
<ul>
<li>Perform a linear regression on all the available variables.</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(data_zambia)

lm_zambia =<span class="st"> </span><span class="kw">lm</span>(<span class="st">`</span><span class="dt">Height for age sd</span><span class="st">`</span> ~<span class="st"> </span>. -<span class="st">`</span><span class="dt">Region:Central</span><span class="st">`</span>-<span class="st"> `</span><span class="dt">Ed:No education</span><span class="st">`</span>, <span class="dt">data =</span> data_zambia)

<span class="co"># We take off two levels to avoid multicollinearity. This should always be done when you create dummies.</span>
<span class="kw">summary</span>(lm_zambia) <span class="co"># read the output understand the benchmark of the factor</span>

lm_zambia_full =<span class="st"> </span><span class="kw">lm</span>(<span class="st">`</span><span class="dt">Height for age sd</span><span class="st">`</span> ~<span class="st"> </span>. , <span class="dt">data =</span> data_zambia)

<span class="kw">summary</span>(lm_zambia_full) <span class="co">#here it is R who choses the benchmark for the factors (i.e. NA variables)</span>

<span class="kw">detach</span>(data_zambia)</code></pre></div>
<blockquote>
<ul>
<li>Reduce the number of covariates (e.g. using the <em>t</em>-test) and add some interactions. Perform a linear regression on the new dataset.</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attach</span>(data_zambia)

<span class="co"># Eliminate variables with t-test in a stepwise manner (fixed alfa = 0.05 in this case)</span>

model_zambia_reduced =<span class="st"> </span><span class="kw">lm</span>(<span class="st">`</span><span class="dt">Height for age sd</span><span class="st">`</span> ~<span class="st"> </span>., <span class="dt">data =</span> data_zambia[,<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">9</span>:<span class="dv">16</span>,<span class="dv">21</span>:<span class="dv">23</span>)])


<span class="kw">summary</span>(model_zambia_reduced) <span class="co"># notice what is happening to the age of the mother variable </span>


<span class="co"># Introduce one interaction in the reduced model. We start with the childsex factor.</span>

model_zambia_int =<span class="st"> </span><span class="kw">lm</span>(<span class="st">`</span><span class="dt">Height for age sd</span><span class="st">`</span> ~<span class="st"> </span>. +<span class="st"> `</span><span class="dt">Breastfeeding duration (months)</span><span class="st">`</span>*<span class="st">`</span><span class="dt">Child sex</span><span class="st">`</span>, <span class="dt">data =</span> data_zambia[,<span class="kw">c</span>(<span class="dv">1</span>:<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">9</span>:<span class="dv">16</span>,<span class="dv">21</span>:<span class="dv">23</span>)])


<span class="kw">summary</span>(model_zambia_int) <span class="co">#We take out the interaction from the model as it is not significant</span>

#### Remember: the hierarchical effect states that anytime you add an interaction also the marginal effects

#### should be part of your model

<span class="kw">detach</span>(data_zambia)</code></pre></div>
<blockquote>
<ul>
<li>Other available procedures for a first model selection in this specific case:</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># (1) VIF (variance inflation factor) for avoiding multicollinearity, </span>

<span class="co"># (2) Automatic Stepwise procedures (e.g. forward and backward) </span>

<span class="co"># (3) Exhaustive search (See practical 3 exercises)</span>

<span class="co"># Example with an automatic stepwise procedure</span>

<span class="kw">help</span>(<span class="st">&quot;step&quot;</span>)

stepwise_procedue =<span class="st"> </span><span class="kw">step</span>(lm_zambia_full,<span class="dt">direction =</span> <span class="st">&quot;backward&quot;</span>) <span class="co">#or forward</span>

<span class="co"># This procedure evaluates, given a criterion, a sequence of variables stopping when</span>
<span class="co"># the criterion is increasing</span></code></pre></div>
<blockquote>
<ul>
<li>Analyse your chosen estimated model with a residual analysis (e.g. residuals vs fitted plot, normal QQ plot etc.).</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Validate your model looking at residuals vs fitted plot and normal QQ plot</span>

<span class="kw">plot</span>(model_zambia_reduced, <span class="dt">which =</span> <span class="dv">1</span>)  <span class="co"># Residuals vs fitted: no particular structure</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(model_zambia_reduced, <span class="dt">which =</span> <span class="dv">2</span>) </code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-28-2.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Normal QQ plot: We observe right tail which is not compatible with a normal assumption</span></code></pre></div>
</div>
<div id="leuk" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Prognostic Factors in Childhood Leukemia</h3>
<blockquote>
<p>Exercises</p>
</blockquote>
<ul>
<li>Load the data from the URL <a href="http://web.stanford.edu/~hastie/CASI_files/DATA/leukemia_big.csv" class="uri">http://web.stanford.edu/~hastie/CASI_files/DATA/leukemia_big.csv</a></li>
</ul>
<div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">leukemia_big &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://web.stanford.edu/~hastie/CASI_files/DATA/leukemia_big.csv&quot;</span>)</code></pre></div>
</div>
<ul>
<li>Create the response variable y according to the number of ALL and AML patients. In the same fashion create the matrix X of independent variables.</li>
</ul>
<p>See <a href="https://web.stanford.edu/~hastie/CASI_files/DATA/leukemia.html" class="uri">https://web.stanford.edu/~hastie/CASI_files/DATA/leukemia.html</a> for further details.</p>
<div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">leukemia_mat =<span class="st"> </span><span class="kw">as.matrix</span>(leukemia_big)

<span class="kw">dim</span>(leukemia_mat)

leukemia_mat =<span class="st"> </span><span class="kw">t</span>(leukemia_mat) <span class="co">#this is the design matrix for the analysis</span>

<span class="co"># Generate the 0 and 1 values for the two different categories: there are 20 ALL, 14 AML, 27 ALL and</span>

<span class="co"># 11 AML for a total of 47 ALL and 25 AML.</span>

<span class="co"># Given the above excerpt from the cancer society, I have decided to code ALL as 1 and AML as 0 since</span>

<span class="co"># doctors are interested in knowing the characteristics which differentiate ALL from AML in order to</span>

<span class="co"># understand if we can use standard treatment or a more aggressive one.</span>

y =<span class="st"> </span><span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">20</span>),<span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">14</span>), <span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">27</span>), <span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">11</span>))  <span class="co">#the response vector</span>

<span class="kw">length</span>(y)

X =<span class="st"> </span>leukemia_mat

<span class="kw">dim</span>(X)</code></pre></div>
</div>
<ul>
<li>Choose the correct exponential family for this situation and perform a GLM on the data. Comment on the results that you obtain.</li>
</ul>
<!-- Since p>>n there are problems -->
<div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">model_glm =<span class="st"> </span><span class="kw">glm</span>(<span class="dt">formula =</span> y ~<span class="st"> </span>X,<span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)


<span class="kw">summary</span>(model_glm)  <span class="co">#singularity issues in the IWLS algorithm of GLM. It is impossible to invert the matrix.</span>

<span class="co"># The binary Lasso is a possible way to solve the issue and have an actual estimate. See glmnet package.</span></code></pre></div>
</div>
</div>
</div>
<div id="chapter-2" class="section level2">
<h2><span class="header-section-number">4.2</span> Chapter 2</h2>
<div id="cv" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Cross-validation</h3>
<p>(solutions provided by <strong>Alexander Maslev</strong>, <strong>Hanxiong Wang</strong> and <strong>Minyoung Lee</strong>). </p>
<p>Program k-fold Cross-Validation (with k=2) and do model selection in a specific simulation setting with an exhaustive search. Follow these steps:</p>
<blockquote>
<ol style="list-style-type: lower-alpha">
<li>Generate from a MVN (multivariate normal) a matrix <span class="math inline">\(\mathbf{X_{n*p}}\)</span> with <span class="math inline">\(n = 1000\)</span> and <span class="math inline">\(p = 5\)</span>. You can choose the location vector as you wish but set the scale matrix as the identity.<br />
</li>
</ol>
</blockquote>
<p>We have chosen the location vector [2,4,6,8,10] and the scale matrix as the identity.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n&lt;-<span class="dv">1000</span>
p&lt;-<span class="dv">5</span>
Mu&lt;-<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">10</span>) <span class="co"># location vector</span>
sigma&lt;-<span class="kw">diag</span>(<span class="dv">5</span>) <span class="co"># scale matrix as the identity</span>
X&lt;-<span class="kw">mvrnorm</span>(n , Mu, sigma)</code></pre></div>
<blockquote>
<ol start="2" style="list-style-type: lower-alpha">
<li>Choose the generating vector <span class="math inline">\(\boldsymbol{\beta }= [3 \; 1.5 \; 0 \; 2 \; 0]\)</span> and retrieve the signal to noise ratio of this setting.<br />
</li>
</ol>
</blockquote>
<p>We found in Wikipedia that the statistical definition of SNR is the reciprocal of the coefficient of variation (i.e. the ratio of mean to standard deviation of a signal or measurement) : <span class="math display">\[SNR = \frac{\mu}{\sigma}\]</span> where <span class="math inline">\(\mu\)</span> is the signal mean or expected value and <span class="math inline">\(\sigma\)</span> is the standard deviation of the noise.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">beta&lt;-<span class="kw">c</span>(<span class="dv">3</span>,<span class="fl">1.5</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>)
e&lt;-<span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)

SNR&lt;-<span class="kw">mean</span>(X%*%beta)/<span class="kw">sqrt</span>(<span class="kw">var</span>(e))

SNR</code></pre></div>
<pre><code>## [1] 27.90095</code></pre>
<p>In the engineering literature, there is an alternative definition:</p>
<p><span class="math display">\[SNR_{eng} = \frac{Var(f(x))}{Var(\epsilon)}\]</span> where <span class="math inline">\(f(x)\)</span> is the chosen prediction rule (e.g. linear function in the OLS case) and <span class="math inline">\(\epsilon\)</span> is the noise. You can fix in advance your SNR with the following code and generate the data accordingly:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">signal_to_noise_ratio =<span class="st"> </span><span class="co">#number to fix as you wish#</span>

data =<span class="st"> </span>X%*%beta

noise =<span class="st"> </span><span class="kw">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)

k =<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(data)/(signal_to_noise_ratio*<span class="kw">var</span>(noise)))


y_hat_eng =<span class="st"> </span>data +<span class="st"> </span>k*noise <span class="co"># how you generate data to retrieve your fixed signal to noise ratio</span></code></pre></div>
<blockquote>
<ol start="3" style="list-style-type: lower-alpha">
<li>Generate <span class="math inline">\(\hat{\mathbf{y}}\)</span> thanks to the relation <span class="math inline">\(\mathbf{y} = \mathbf{X_{n*p}} \; \boldsymbol{\beta} + \boldsymbol{\epsilon}\)</span> where <span class="math inline">\(\epsilon_{i}\)</span> is a standard normal, <span class="math inline">\(n = 1000\)</span> and <span class="math inline">\(p = 5\)</span>. Suppose for simplicity that the errors are uncorrelated.<br />
</li>
</ol>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Y_hat&lt;-X%*%beta+e</code></pre></div>
<blockquote>
<ol start="4" style="list-style-type: lower-alpha">
<li>Split the data randomly in two halves (k=2) and use the training set to determine <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>. Then, compute the squared loss function as prediction error measure for each possible model. Observe which model is the best model.<br />
</li>
</ol>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:n, <span class="dt">size=</span><span class="fl">0.5</span>*n)

<span class="co"># Split data</span>
y_train&lt;-<span class="st"> </span>Y_hat[-index,]
x_train&lt;-X[-index,]
y_test&lt;-<span class="st"> </span>Y_hat[index,]
x_test&lt;-X[index,]

index_sub_choose&lt;-<span class="kw">c</span>(<span class="dv">1</span>:p)
sub_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> <span class="ot">NA</span>,<span class="dt">ncol =</span> p,<span class="dt">nrow =</span> <span class="dv">2</span>^p<span class="dv">-1</span>)
t=<span class="dv">0</span>
for(i in <span class="dv">1</span>:<span class="dv">5</span>)
{
  index_matrix &lt;-<span class="st"> </span><span class="kw">combn</span>(index_sub_choose,i)
  for(j in <span class="dv">1</span>:<span class="kw">ncol</span>(index_matrix))
  {
    t &lt;-<span class="st"> </span>t<span class="dv">+1</span>
    index_sub &lt;-<span class="st"> </span>index_matrix[,j]
    sub_matrix[t,<span class="kw">c</span>(index_sub)]  &lt;-<span class="st">  </span><span class="dv">1</span>
  }
}

k&lt;-<span class="kw">nrow</span>(sub_matrix)
cv &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data=</span><span class="ot">NA</span>,<span class="dt">nrow =</span> k,<span class="dt">ncol =</span> <span class="dv">1</span>)
for(j in <span class="dv">1</span>:k){
  Xsub    &lt;-x_train[,<span class="kw">which</span>(sub_matrix[j,]==<span class="dv">1</span>)]
  betaMLE &lt;-<span class="kw">solve</span>(<span class="kw">t</span>(Xsub)%*%Xsub)%*%<span class="kw">t</span>(Xsub)%*%y_train
  new_Y   &lt;-x_test[,<span class="kw">which</span>(sub_matrix[j,]==<span class="dv">1</span>)]%*%betaMLE
  cv[j,]      &lt;-<span class="st"> </span><span class="kw">t</span>(y_test-new_Y)%*%(y_test-new_Y)
  
}

BEST_cv&lt;-<span class="kw">which</span>(sub_matrix[<span class="kw">which.min</span>(cv),]==<span class="dv">1</span>)
BEST_cv</code></pre></div>
<pre><code>## [1] 1 2 4 5</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Xsub_cv&lt;-x_train[,BEST_cv]
betaMLE_cv&lt;-<span class="kw">solve</span>(<span class="kw">t</span>(Xsub_cv)%*%Xsub_cv)%*%<span class="kw">t</span>(Xsub_cv)%*%y_train
betaMLE_cv</code></pre></div>
<pre><code>##             [,1]
## [1,]  3.03433961
## [2,]  1.51075393
## [3,]  2.01760617
## [4,] -0.02911818</code></pre>
<p>Each time it changes but most of the times we obtain the best model when p=5. The beta sometimes is not close to generating vector <span class="math inline">\(\beta\)</span> = [3 1.5 0 2 0].</p>
<blockquote>
<ol start="5" style="list-style-type: lower-alpha">
<li>Suppose now that we increase the size of <span class="math inline">\(\boldsymbol{\beta}\)</span> to 100 (i.e. <span class="math inline">\(p = 100\)</span> ). Calculate the number of possible models to evaluate together with an estimate of the time needed for an exhaustive search (<em>hint: use previous results</em>). Conclude on the feasibility of this task.</li>
</ol>
</blockquote>
<pre><code>## [1] 1.267651e+30</code></pre>
<pre><code>## [1] 6.915153e+27</code></pre>
<p>When we run a CV process with p=5, it takes 0.1691079 seconds. For p = 5, we can have 31 different models thanks to Newton’s binomial theorem (i.e. <span class="math inline">\(2^p - 1\)</span>). Unfortunately when we increase p to 100, we have 1.26e+30 different models. Thus it will take approximately 1.9e+24 hours. This is the case when we do k=2 cross validation. Moreover if we increase the number of k, we will drastically increase the time needed. This task is not feasible.</p>
</div>
<div id="aic" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Akaike Information Criterion</h3>
<p>(solutions provided by <strong>Alexander Maslev</strong>, <strong>Hanxiong Wang</strong> and <strong>Minyoung Lee</strong>). </p>
<blockquote>
<ul>
<li>Program AIC and do model selection in a specific simulation setting with an exhaustive search (follow the passages listed in the CV exercise section).<br />
</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n&lt;-<span class="dv">1000</span>
p&lt;-<span class="dv">5</span>
Mu&lt;-<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">10</span>) <span class="co"># location vector</span>
sigma&lt;-<span class="kw">diag</span>(<span class="dv">5</span>) <span class="co"># scale matrix as the identity</span>
X&lt;-<span class="kw">mvrnorm</span>(n , Mu, sigma)

beta&lt;-<span class="kw">c</span>(<span class="dv">3</span>,<span class="fl">1.5</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>)
e&lt;-<span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)
SNR&lt;-<span class="kw">mean</span>(X%*%beta)/<span class="kw">var</span>(e)

Y_hat&lt;-X%*%beta+e</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">index_sub_choose&lt;-<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>)
sub_matrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data =</span> <span class="ot">NA</span>,<span class="dt">ncol =</span> <span class="dv">5</span>,<span class="dt">nrow =</span> <span class="dv">31</span>)
t=<span class="dv">0</span>
for(i in <span class="dv">1</span>:<span class="dv">5</span>)
{
  index_matrix &lt;-<span class="st"> </span><span class="kw">combn</span>(index_sub_choose,i)
  for(j in <span class="dv">1</span>:<span class="kw">ncol</span>(index_matrix))
  {
    t &lt;-<span class="st"> </span>t<span class="dv">+1</span>
    index_sub &lt;-<span class="st"> </span>index_matrix[,j]
    sub_matrix[t,<span class="kw">c</span>(index_sub)]  &lt;-<span class="st">  </span><span class="dv">1</span>
  }
}

<span class="co"># AIC</span>
RSS&lt;-<span class="kw">rep</span>(<span class="dv">0</span>,k)
AIC&lt;-<span class="kw">rep</span>(<span class="dv">0</span>,k)
k&lt;-<span class="kw">nrow</span>(sub_matrix)
for(j in <span class="dv">1</span>:k){
Xsub&lt;-<span class="kw">as.matrix</span>(X[,<span class="kw">which</span>(sub_matrix[j,]==<span class="dv">1</span>)])
betaMLE&lt;-<span class="kw">solve</span>(<span class="kw">t</span>(Xsub)%*%Xsub)%*%<span class="kw">t</span>(Xsub)%*%Y_hat
new_Y&lt;-Xsub%*%betaMLE
for(i in <span class="dv">1</span>:(n/<span class="dv">2</span>)){
  RSS[j]&lt;-RSS[j]+(new_Y[i]-Y_hat[i])^<span class="dv">2</span>
}
AIC[j]&lt;-RSS[j]/<span class="kw">var</span>(e)+<span class="dv">2</span>*<span class="kw">ncol</span>(Xsub)
}
BEST&lt;-<span class="kw">which</span>(sub_matrix[<span class="kw">which.min</span>(AIC),]==<span class="dv">1</span>)
BEST</code></pre></div>
<pre><code>## [1] 1 2 4</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Xsub&lt;-<span class="kw">as.matrix</span>(X[,BEST])
betaMLE&lt;-<span class="kw">solve</span>(<span class="kw">t</span>(Xsub)%*%Xsub)%*%<span class="kw">t</span>(Xsub)%*%Y_hat
betaMLE</code></pre></div>
<pre><code>##          [,1]
## [1,] 2.982799
## [2,] 1.440587
## [3,] 2.035385</code></pre>
<p>Each time it changes but most of the times we obtain the best model when p=4 in position[1 2 4 5]. The estimated beta is very close to generating vector <span class="math inline">\(\beta\)</span> = [3 1.5 0 2 0].</p>
<p>The above results hold not considering <span class="math inline">\(\sigma\)</span> and the intercept as parameters. In the general formulation of the Akaike’s information criterion, <span class="math inline">\(p = dim(\Theta)\)</span> where <span class="math inline">\(\Theta\)</span> is the parameters space.</p>
<p>As we computed in point (e) in CV exercise, when p = 100, we have 1.26e+30 different model. The time needed to run the AIC process with p = 5 takes 0.2441621 seconds. When we calculate the time that we need to run when p = 100, we obtain approximately 2.7e+24 hours. Thus we still think that the task to do all the combinations when p = 100 is not feasible.</p>
<pre><code>## [1] 1.267651e+30</code></pre>
<pre><code>## [1] 9.984266e+27</code></pre>
<pre><code>## [1] 2.773407e+24</code></pre>
<blockquote>
<ul>
<li>Compare the performance of your programmed CV and AIC by replicating 100 times the tasks. In particular you should evaluate three specific criteria: the proportion of times the correct model is selected (<em>Exact</em>), the proportion of times the selected model contains the correct one (<em>Correct</em>) and the average number of selected regressors (<em>Average <span class="math inline">\(\sharp\)</span></em>)<br />
</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">## Rep 100 times AIC

cv &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data=</span><span class="ot">NA</span>,<span class="dt">nrow =</span> k,<span class="dt">ncol =</span> <span class="dv">1</span>)
Exact&lt;-<span class="kw">data.frame</span>(<span class="kw">t</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)))
<span class="kw">colnames</span>(Exact)&lt;-<span class="kw">c</span>(<span class="st">&quot;AIC&quot;</span>,<span class="st">&quot;CV&quot;</span>)
AverageN&lt;-<span class="kw">matrix</span>(<span class="ot">NA</span>,<span class="dt">nrow=</span><span class="dv">100</span>,<span class="dt">ncol =</span> <span class="dv">2</span>)
<span class="kw">colnames</span>(AverageN)&lt;-<span class="kw">c</span>(<span class="st">&quot;AIC&quot;</span>,<span class="st">&quot;CV&quot;</span>)
Correct&lt;-<span class="kw">data.frame</span>(<span class="kw">t</span>(<span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>)))
<span class="kw">colnames</span>(Correct)&lt;-<span class="kw">c</span>(<span class="st">&quot;AIC&quot;</span>,<span class="st">&quot;CV&quot;</span>)

for(l in <span class="dv">1</span>:<span class="dv">100</span>){
  
### SETTING ###
  n&lt;-<span class="dv">1000</span>
  p&lt;-<span class="dv">5</span>
  Mu&lt;-<span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">10</span>) <span class="co"># location vector</span>
  sigma&lt;-<span class="kw">diag</span>(<span class="dv">5</span>) <span class="co"># scale matrix as the identity</span>
  X&lt;-<span class="kw">mvrnorm</span>(n , Mu, sigma)
  beta&lt;-<span class="kw">c</span>(<span class="dv">3</span>,<span class="fl">1.5</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">0</span>)
  e&lt;-<span class="kw">rnorm</span>(n, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>)
  Y_hat&lt;-X%*%beta+e

### AIC ###    
  RSS&lt;-<span class="kw">rep</span>(<span class="dv">0</span>,k)
  AIC&lt;-<span class="kw">rep</span>(<span class="dv">0</span>,k)

  for(j in <span class="dv">1</span>:k){
    Xsub&lt;-<span class="kw">as.matrix</span>(X[,<span class="kw">which</span>(sub_matrix[j,]==<span class="dv">1</span>)])
    betaMLE&lt;-<span class="kw">solve</span>(<span class="kw">t</span>(Xsub)%*%Xsub)%*%<span class="kw">t</span>(Xsub)%*%Y_hat
    new_Y&lt;-Xsub%*%betaMLE
    for(i in <span class="dv">1</span>:(n/<span class="dv">2</span>)){
      RSS[j]&lt;-RSS[j]+(new_Y[i]-Y_hat[i])^<span class="dv">2</span>
    }
    AIC[j]&lt;-RSS[j]/<span class="kw">var</span>(e)+<span class="dv">2</span>*<span class="kw">ncol</span>(Xsub)
  }
  BEST&lt;-sub_matrix[<span class="kw">which.min</span>(AIC),]
  BEST[<span class="kw">is.na</span>(BEST)] &lt;-<span class="dv">0</span>
  if(<span class="kw">sum</span>(BEST-<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>))==<span class="dv">0</span>){
    
    Exact[<span class="dv">1</span>]&lt;-Exact[<span class="dv">1</span>]+<span class="dv">1</span>
    
  }
  if(<span class="kw">sum</span>((BEST[<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>)]-<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)))==<span class="dv">0</span>){
    Correct[<span class="dv">1</span>]&lt;-Correct[<span class="dv">1</span>]+<span class="dv">1</span>
  }
    AverageN[l,<span class="dv">1</span>]&lt;-<span class="kw">sum</span>(BEST)
  
  
### CV ###
  index &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:n, <span class="dt">size=</span><span class="fl">0.5</span>*n)
  y_train&lt;-<span class="st"> </span>Y_hat[-index,]
  x_train&lt;-X[-index,]
  y_test&lt;-<span class="st"> </span>Y_hat[index,]
  x_test&lt;-X[index,]
  
  for(j in <span class="dv">1</span>:k){
    Xsub    &lt;-x_train[,<span class="kw">which</span>(sub_matrix[j,]==<span class="dv">1</span>)]
    betaMLE &lt;-<span class="kw">solve</span>(<span class="kw">t</span>(Xsub)%*%Xsub)%*%<span class="kw">t</span>(Xsub)%*%y_train
    new_Y   &lt;-x_test[,<span class="kw">which</span>(sub_matrix[j,]==<span class="dv">1</span>)]%*%betaMLE
    cv[j,]      &lt;-<span class="st"> </span><span class="kw">t</span>(y_test-new_Y)%*%(y_test-new_Y)
    
  }
  
  BEST_cv&lt;-sub_matrix[<span class="kw">which.min</span>(cv),]
  BEST_cv[<span class="kw">is.na</span>(BEST_cv)] &lt;-<span class="dv">0</span>
  if(<span class="kw">sum</span>(BEST_cv-<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>))==<span class="dv">0</span>){
    
    Exact[<span class="dv">2</span>]&lt;-Exact[<span class="dv">2</span>]+<span class="dv">1</span>
    
  }
  if(<span class="kw">sum</span>((BEST_cv[<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>)]-<span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>)))==<span class="dv">0</span>){
    Correct[<span class="dv">2</span>]&lt;-Correct[<span class="dv">2</span>]+<span class="dv">1</span>
  }
    AverageN[l,<span class="dv">2</span>]&lt;-<span class="kw">sum</span>(BEST_cv)
   
}

Exact/<span class="dv">100</span></code></pre></div>
<pre><code>##    AIC   CV
## 1 0.84 0.47</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Correct/<span class="dv">100</span></code></pre></div>
<pre><code>##   AIC CV
## 1   1  1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colMeans</span>(AverageN)</code></pre></div>
<pre><code>##  AIC   CV 
## 3.20 3.63</code></pre>
<p>In this part, we have simulated the AIC process and the CV process for 100 times and evaluated the three criteria. We have found that AIC gives better results than CV in terms of Exact models and it has a lower number of selected regressors on average. Both methods achieves model selection consistency in this simple setting as the proportion of correct models reaches the value of 1.</p>
<p>This result is expected since AIC is derived from the likelihood which inherits all the nice properties (e.g. Cramer-Rao bound etc.) when the model is correct. On the other hand, CV is a non parametric method thus inferior by definition to the AIC in this setting. However in a real application our conjectured model maybe far from the truth and CV could be a better choice.</p>
<blockquote>
<ul>
<li>In the same simulation setting outlined in the CV exercise section, generate from a MVN (multivariate normal) a matrix <span class="math inline">\(\mathbf{X_{n*p}}\)</span> with <span class="math inline">\(n = 1000\)</span> and <span class="math inline">\(p = 5\)</span> but now fix the scale matrix with an autoregressive form <span class="math inline">\(\boldsymbol{\Sigma}=[\sigma_{lm}]_{l,m=1,\ldots,p}\)</span> with <span class="math inline">\(\sigma_{lm} = \rho^{\mid l - m\mid}\)</span>. Compare the performance of CV and AIC for <span class="math inline">\(\boldsymbol{\rho} = [0.2 \; 0.5\; 0.7]\)</span> (<span class="math inline">\(\rho = 0\)</span> corresponds to the identity case that you have already treated).<br />
</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>Upload the <a href="https://github.com/CaesarXVII/MSHD-book-and-datasets/blob/master/datasets/malnutrion_zambia_cleaned.Rda">Zambia dataset</a> and perform an exhaustive search on the continuous covariates (i.e. avoiding factors) based on CV and AIC in order to find the best model. You can either employ your codes derived in previous exercises or make use of the existing R packages: <em>leaps</em>, <em>glmulti</em>, <em>MuMIn</em> and <em>caret</em>.<br />
</li>
</ul>
</blockquote>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load Zambia dataset </span>

<span class="kw">load</span>(<span class="dt">file =</span> <span class="st">&quot;your_directory/data_zambia.Rda&quot;&quot;)</span>

<span class="st">data_zambia = data_zambia[,c(1:7,21,22,24)] #exclude the factors from the analysis</span>


<span class="st">### Exhaustive search with leaps (AIC case) ###</span>

<span class="st">require(leaps)</span>

<span class="st">regsubsets.out &lt;- regsubsets(data_zambia$`Height for age sd` ~ .,data = data_zambia,nbest = 1,</span>
<span class="st">                             nvmax = NULL,    # NULL for no limit on number of variables</span>
<span class="st">                             force.in = NULL, force.out = NULL,</span>
<span class="st">                             method = &quot;</span>exhaustive<span class="st">&quot;)</span>

<span class="st">summary(regsubsets.out)</span>


<span class="st">plot(regsubsets.out) # BIC is default</span>

<span class="st">plot(regsubsets.out,scale = &quot;</span>Cp<span class="st">&quot;) #C_p case which is equal to AIC with a linear model</span>


<span class="st">### Exhaustive search with glmulti (AIC case) ### </span>


<span class="st">glmulti.lm.out &lt;- glmulti::glmulti(data_zambia$`Height for age sd` ~ .,data = data_zambia,</span>
<span class="st">          level = 1,               # No interaction considered</span>
<span class="st">          method = &quot;</span>h<span class="st">&quot;,            # Exhaustive approach</span>
<span class="st">          crit = &quot;</span>aic<span class="st">&quot;,            # AIC as criteria</span>
<span class="st">          confsetsize = 5,         # Keep 5 best models</span>
<span class="st">          plotty = F, report = F,  # No plot or interim reports</span>
<span class="st">          fitfunction = &quot;</span>lm<span class="st">&quot;)      # lm function</span>



<span class="st">### Exhaustive search with MumIn (AIC case) ###</span>

<span class="st">require(MuMIn)</span>


<span class="st">data_model &lt;- lm(data_zambia$`Height for age sd` ~ .,data = data_zambia)</span>


<span class="st">combinations &lt;- dredge(data_model)</span>

<span class="st">print(combinations)</span>


<span class="st">### Exhaustive search with caret (CV case and AIC case) ###</span>

<span class="st">require(caret)</span>

<span class="st">attach(data_zambia)</span>

<span class="st"># Unfortunately there is no exhaustive search based on CV in Caret, it is just stepwise.</span>

<span class="st">#setting up 10-fold cross-validation</span>

<span class="st">control &lt;- trainControl(method=&quot;</span>cv<span class="st">&quot;, number=10) </span>

<span class="st">#finding the ideal model by AIC criterion</span>

<span class="st">model_AIC = train(`Height for age sd`~.,data=data_zambia,method=&quot;</span>lmStepAIC<span class="st">&quot;,trControl=control)</span>

<span class="st">#finding the ideal model by mean square error</span>

<span class="st">modelCV = train(`Height for age sd`~.,data=data_zambia,method=&quot;</span>lm<span class="st">&quot;,trControl=control)</span>

<span class="st">detach(data_zambia)</span>

<span class="st"># In order to do a full exhaustive search with CV, we should exploit the codes produced in CV exercise. Of course </span>
<span class="st"># as the number of variables increase, the task becomes impossible.</span></code></pre></div>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ordering-the-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
